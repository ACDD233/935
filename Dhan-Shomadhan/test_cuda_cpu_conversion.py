#!/usr/bin/env python3
"""
æµ‹è¯• CUDA åˆ° CPU è½¬æ¢ä¿®å¤
"""
import torch
import numpy as np
from ultralytics import YOLO

def test_cuda_to_cpu_conversion():
    """æµ‹è¯• CUDA åˆ° CPU è½¬æ¢ä¿®å¤"""
    print("=" * 60)
    print("æµ‹è¯• CUDA åˆ° CPU è½¬æ¢ä¿®å¤")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ CUDA å¯ç”¨æ€§
    if torch.cuda.is_available():
        device = 'cuda'
        print(f"âœ… CUDA å¯ç”¨ï¼Œä½¿ç”¨è®¾å¤‡: {device}")
    else:
        device = 'cpu'
        print(f"âœ… ä½¿ç”¨ CPU è®¾å¤‡: {device}")
    
    # 2. åŠ è½½æ¨¡å‹
    model_path = "Dhan-Shomadhan/1343258/models/fold_1_best.pt"
    try:
        yolo_model = YOLO(model_path)
        torch_model = yolo_model.model
        torch_model.eval()
        
        # ç¡®ä¿æ¨¡å‹åœ¨æ­£ç¡®çš„è®¾å¤‡ä¸Š
        torch_model = torch_model.to(device)
        print("âœ… YOLO æ¨¡å‹åŠ è½½æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ YOLO æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return False
    
    # 3. åˆ›å»ºæµ‹è¯•è¾“å…¥
    try:
        test_input = torch.randn(1, 3, 320, 320).to(device)
        print(f"âœ… æµ‹è¯•è¾“å…¥åˆ›å»ºæˆåŠŸï¼Œè®¾å¤‡: {test_input.device}")
        
    except Exception as e:
        print(f"âŒ æµ‹è¯•è¾“å…¥åˆ›å»ºå¤±è´¥: {e}")
        return False
    
    # 4. æµ‹è¯•æ¨¡å‹è¾“å‡º
    try:
        with torch.no_grad():
            outputs = torch_model(test_input)
            print(f"âœ… æ¨¡å‹è¾“å‡ºç±»å‹: {type(outputs)}")
            
            # å¤„ç†è¾“å‡ºæ ¼å¼
            if isinstance(outputs, tuple):
                main_output = outputs[0]
                print(f"âœ… å…ƒç»„è¾“å‡ºï¼Œä¸»è¾“å‡ºç±»å‹: {type(main_output)}")
            else:
                main_output = outputs
                print(f"âœ… å•ä¸ªè¾“å‡ºç±»å‹: {type(main_output)}")
            
            # æµ‹è¯• CUDA åˆ° CPU è½¬æ¢
            if hasattr(main_output, 'probs'):
                print("âœ… ä½¿ç”¨ probs å±æ€§")
                try:
                    # æ­£ç¡®çš„è½¬æ¢æ–¹å¼
                    pred_probs = main_output.probs.data.cpu().numpy()
                    pred_class = main_output.probs.top1
                    print(f"âœ… CUDA åˆ° CPU è½¬æ¢æˆåŠŸ")
                    print(f"âœ… é¢„æµ‹æ¦‚ç‡å½¢çŠ¶: {pred_probs.shape}")
                    print(f"âœ… é¢„æµ‹ç±»åˆ«: {pred_class}")
                except Exception as e:
                    print(f"âŒ CUDA åˆ° CPU è½¬æ¢å¤±è´¥: {e}")
                    return False
            else:
                if isinstance(main_output, torch.Tensor):
                    print("âœ… ä½¿ç”¨å¼ é‡ softmax")
                    try:
                        # æ­£ç¡®çš„è½¬æ¢æ–¹å¼
                        pred_probs = torch.softmax(main_output, dim=1).detach().cpu().numpy()[0]
                        pred_class = main_output.argmax(dim=1).item()
                        print(f"âœ… CUDA åˆ° CPU è½¬æ¢æˆåŠŸ")
                        print(f"âœ… é¢„æµ‹æ¦‚ç‡å½¢çŠ¶: {pred_probs.shape}")
                        print(f"âœ… é¢„æµ‹ç±»åˆ«: {pred_class}")
                    except Exception as e:
                        print(f"âŒ CUDA åˆ° CPU è½¬æ¢å¤±è´¥: {e}")
                        return False
                else:
                    print("âŒ ä¸»è¾“å‡ºæ—¢ä¸æ˜¯å¼ é‡ä¹Ÿæ²¡æœ‰ probs å±æ€§")
                    return False
                    
    except Exception as e:
        print(f"âŒ æ¨¡å‹è¾“å‡ºæµ‹è¯•å¤±è´¥: {e}")
        return False
    
    # 5. æµ‹è¯•é”™è¯¯çš„è½¬æ¢æ–¹å¼ï¼ˆåº”è¯¥å¤±è´¥ï¼‰
    print("\næµ‹è¯•é”™è¯¯çš„è½¬æ¢æ–¹å¼:")
    try:
        test_tensor = torch.randn(1, 3, 320, 320).to(device)
        # é”™è¯¯çš„è½¬æ¢æ–¹å¼ï¼ˆåº”è¯¥å¤±è´¥ï¼‰
        wrong_result = test_tensor.numpy()
        print("âŒ é”™è¯¯è½¬æ¢æ–¹å¼ä¸åº”è¯¥æˆåŠŸ")
        return False
    except Exception as e:
        print(f"âœ… é”™è¯¯è½¬æ¢æ–¹å¼æ­£ç¡®å¤±è´¥: {e}")
    
    print("\nğŸ‰ CUDA åˆ° CPU è½¬æ¢æµ‹è¯•é€šè¿‡!")
    return True

if __name__ == '__main__':
    test_cuda_to_cpu_conversion()
